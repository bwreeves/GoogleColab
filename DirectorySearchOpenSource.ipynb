{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bwreeves/GoogleColab/blob/main/DirectorySearchOpenSource.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZv36yosu-00"
      },
      "outputs": [],
      "source": [
        "print(\"Hello XponentL\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install statements\n",
        "!pip install langchain\n",
        "!pip install pinecone-client\n",
        "!pip install sentence_transformers\n",
        "!pip install InstructorEmbedding\n",
        "!pip install sentence_transformers\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "7zTMh48QB9vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import statements\n",
        "#loader and splitter\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "#pipeline to bring in Flan-T5\n",
        "from transformers import pipeline\n",
        "#to import llm object\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "#embeddings\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "#vector store\n",
        "from langchain.vectorstores import Pinecone\n",
        "import pinecone\n",
        "#retriever\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "12ywEdSMDPvF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import the model using a pipeline. I used base becuase my ram crashes eventually if I use bigger. \n",
        "model = pipeline(model=\"google/flan-t5-base\", max_size=512, truncation=True)\n",
        "model.save_pretrained(\"~/flan-t5-base\")"
      ],
      "metadata": {
        "id": "PCH8zK3vFeh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect google drive to import a folder without needing to zip/unzip\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "REJEof9sH7rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load directory\n",
        "path = \"/content/gdrive/MyDrive/PdfsForLLM\"\n",
        "loader = PyPDFDirectoryLoader(path)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "Df7ptqoqGF-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)\n",
        "print(len(data))"
      ],
      "metadata": {
        "id": "knb76h39HKQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create embeddings object\n",
        "hf = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "ebmeddings = hf"
      ],
      "metadata": {
        "id": "LtRDD5GXNSgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#connect to pinecone and import docs\n",
        "pinecone.init(\n",
        "    api_key=\"920e41ab-b0cb-48f4-9c9b-23208a1fa1bb\", environment=\"us-central1-gcp\"\n",
        ")\n",
        "index_name = \"search-document\"\n",
        "docsearch = Pinecone.from_documents(texts, ebmeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "fiRH2CodNsOR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the llm object\n",
        "llm = HuggingFacePipeline.from_model_id(model_id=\"google/flan-t5-base\", task=\"text2text-generation\",\n",
        "                          model_kwargs={\"temperature\":0})"
      ],
      "metadata": {
        "id": "U16_Gn3rPMK9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make the retrieval, seed it with low token size, include sources\n",
        "retriever = docsearch.as_retriever(search_kwargs={\"k\":1})\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever,\n",
        "                            return_source_documents=True)"
      ],
      "metadata": {
        "id": "sySTuasUQ5G6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#question 1 pulls from pdf4\n",
        "answer = qa(\"How do you know if a poset is well ordered\")\n",
        "print(answer[\"result\"])\n",
        "for i in answer[\"source_documents\"]:\n",
        "  print(i.metadata[\"source\"])\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "FfovuxUpRyJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#question 2 pulls from pd2\n",
        "answer2 = qa(\"What does it mean to be relatively prime?\")\n",
        "print(answer2[\"result\"])\n",
        "for i in answer2[\"source_documents\"]:\n",
        "  print(i.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "q6HLO9EqSrrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#question 3 pulls from pdf 5\n",
        "answer3 = qa(\"Proof with mathematical induction?\")\n",
        "print(answer3[\"result\"])\n",
        "for i in answer3[\"source_documents\"]:\n",
        "  print(i.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "_-E4xZrhUCBL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}